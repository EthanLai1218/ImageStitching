{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab55de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stitcher:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def stitch(self, imgs, blending_mode = \"linearBlending\", ratio = 0.75):\n",
    "        '''\n",
    "            The main method to stitch image\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        print(\"Left img size (\", hl, \"*\", wl, \")\")\n",
    "        print(\"Right img size (\", hr, \"*\", wr, \")\")\n",
    "        \n",
    "        # Step1 - extract the keypoints and features by SIFT detector and descriptor\n",
    "        print(\"Step1 - Extract the keypoints and features by SIFT detector and descriptor...\")\n",
    "        kps_l, features_l = self.detectAndDescribe(img_left)\n",
    "        kps_r, features_r = self.detectAndDescribe(img_right)\n",
    "        \n",
    "\n",
    "        # Step2 - extract the match point with threshold (David Lowe’s ratio test)\n",
    "        print(\"Step2 - Extract the match point with threshold (David Lowe’s ratio test)...\")\n",
    "        matches_pos = self.matchKeyPoint(kps_l, kps_r, features_l, features_r, ratio)\n",
    "        print(\"The number of matching points:\", len(matches_pos))\n",
    "        \n",
    "        # Step2 - draw the img with matching point and their connection line\n",
    "        self.drawMatches([img_left, img_right], matches_pos)\n",
    "        \n",
    "        # Step3 - fit the homography model with RANSAC algorithm\n",
    "        print(\"Step3 - Fit the best homography model with RANSAC algorithm...\")\n",
    "        HomoMat = self.fitHomoMat(matches_pos)\n",
    "        \n",
    "    \n",
    "        # Step4 - Warp image to create panoramic image\n",
    "        print(\"Step4 - Warp image to create panoramic image...\")\n",
    "        warp_img = self.warp([img_left, img_right], HomoMat, blending_mode) \n",
    "        \n",
    "        return warp_img\n",
    "    \n",
    "    def detectAndDescribe(self, img):\n",
    "        '''\n",
    "        The Detector and Descriptor\n",
    "        '''\n",
    "        # SIFT detector and descriptor\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        kps, features = sift.detectAndCompute(img,None)\n",
    "        \n",
    "        return kps, features\n",
    "    \n",
    "    def matchKeyPoint(self, kps_l, kps_r, features_l, features_r, ratio):\n",
    "        '''\n",
    "            Match the Keypoints beteewn two image\n",
    "        '''\n",
    "        Match_idxAndDist = [] # min corresponding index, min distance, seccond min corresponding index, second min distance\n",
    "        for i in range(len(features_l)):\n",
    "            min_IdxDis = [-1, np.inf]  # record the min corresponding index, min distance\n",
    "            secMin_IdxDis = [-1 ,np.inf]  # record the second corresponding min index, min distance\n",
    "            for j in range(len(features_r)):\n",
    "                dist = np.linalg.norm(features_l[i] - features_r[j])\n",
    "                if (min_IdxDis[1] > dist):\n",
    "                    secMin_IdxDis = np.copy(min_IdxDis)\n",
    "                    min_IdxDis = [j , dist]\n",
    "                elif (secMin_IdxDis[1] > dist and secMin_IdxDis[1] != min_IdxDis[1]):\n",
    "                    secMin_IdxDis = [j, dist]\n",
    "            \n",
    "            Match_idxAndDist.append([min_IdxDis[0], min_IdxDis[1], secMin_IdxDis[0], secMin_IdxDis[1]])\n",
    "\n",
    "        # ratio test as per Lowe's paper\n",
    "        goodMatches = []\n",
    "        for i in range(len(Match_idxAndDist)):\n",
    "            if (Match_idxAndDist[i][1] <= Match_idxAndDist[i][3] * ratio):\n",
    "                goodMatches.append((i, Match_idxAndDist[i][0]))\n",
    "            \n",
    "        goodMatches_pos = []\n",
    "        for (idx, correspondingIdx) in goodMatches:\n",
    "            psA = (int(kps_l[idx].pt[0]), int(kps_l[idx].pt[1]))\n",
    "            psB = (int(kps_r[correspondingIdx].pt[0]), int(kps_r[correspondingIdx].pt[1]))\n",
    "            goodMatches_pos.append([psA, psB])\n",
    "            \n",
    "        return goodMatches_pos\n",
    "    \n",
    "    def drawMatches(self, imgs, matches_pos):\n",
    "        '''\n",
    "            Draw the match points img with keypoints and connection line\n",
    "        '''\n",
    "        \n",
    "        # initialize the output visualization image\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        vis = np.zeros((max(hl, hr), wl + wr, 3), dtype=\"uint8\")\n",
    "        vis[0:hl, 0:wl] = img_left\n",
    "        vis[0:hr, wl:] = img_right\n",
    "        \n",
    "        # Draw the match\n",
    "        for (img_left_pos, img_right_pos) in matches_pos:\n",
    "\n",
    "                pos_l = img_left_pos\n",
    "                pos_r = img_right_pos[0] + wl, img_right_pos[1]\n",
    "                cv2.circle(vis, pos_l, 3, (0, 0, 255), 1)\n",
    "                cv2.circle(vis, pos_r, 3, (0, 255, 0), 1)\n",
    "                cv2.line(vis, pos_l, pos_r, (255, 0, 0), 1)\n",
    "                \n",
    "        # return the visualization\n",
    "        plt.figure(4)\n",
    "        plt.title(\"img with matching points\")\n",
    "        plt.imshow(vis[:,:,::-1])\n",
    "        #cv2.imwrite(\"Feature matching img/matching.jpg\", vis)\n",
    "        \n",
    "        return vis\n",
    "    \n",
    "    def fitHomoMat(self, matches_pos):\n",
    "        '''\n",
    "            Fit the best homography model with RANSAC algorithm - noBlending、linearBlending、linearBlendingWithConstant\n",
    "        '''\n",
    "        dstPoints = [] # i.e. left image(destination image)\n",
    "        srcPoints = [] # i.e. right image(source image) \n",
    "        for dstPoint, srcPoint in matches_pos:\n",
    "            dstPoints.append(list(dstPoint)) \n",
    "            srcPoints.append(list(srcPoint))\n",
    "        dstPoints = np.array(dstPoints)\n",
    "        srcPoints = np.array(srcPoints)\n",
    "        \n",
    "        homography = Homography()\n",
    "        \n",
    "        # RANSAC algorithm, selecting the best fit homography\n",
    "        NumSample = len(matches_pos)\n",
    "        threshold = 5.0  \n",
    "        NumIter = 8000\n",
    "        NumRamdomSubSample = 4\n",
    "        MaxInlier = 0\n",
    "        Best_H = None\n",
    "        \n",
    "        for run in range(NumIter):\n",
    "            SubSampleIdx = random.sample(range(NumSample), NumRamdomSubSample) # get the Index of ramdom sampling\n",
    "            H = homography.solve_homography(srcPoints[SubSampleIdx], dstPoints[SubSampleIdx])\n",
    "            \n",
    "            # find the best Homography have the the maximum number of inlier\n",
    "            NumInlier = 0 \n",
    "            for i in range(NumSample):\n",
    "                if i not in SubSampleIdx:\n",
    "                    concateCoor = np.hstack((srcPoints[i], [1])) # add z-axis as 1\n",
    "                    dstCoor = H @ concateCoor.T # calculate the coordination after transform to destination img \n",
    "                    if dstCoor[2] <= 1e-8: # avoid divide zero number, or too small number cause overflow\n",
    "                        continue\n",
    "                    dstCoor = dstCoor / dstCoor[2]\n",
    "                    if (np.linalg.norm(dstCoor[:2] - dstPoints[i]) < threshold):\n",
    "                        NumInlier = NumInlier + 1\n",
    "            if (MaxInlier < NumInlier):\n",
    "                MaxInlier = NumInlier\n",
    "                Best_H = H\n",
    "                \n",
    "        print(\"The Number of Maximum Inlier:\", MaxInlier)\n",
    "        \n",
    "        return Best_H\n",
    "    \n",
    "    def warp(self, imgs, HomoMat, blending_mode):\n",
    "        '''\n",
    "           Warp image to create panoramic image\n",
    "           There are three different blending method - noBlending、linearBlending、linearBlendingWithConstant\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        stitch_img = np.zeros( (max(hl, hr), wl + wr, 3), dtype=\"int\") # create the (stitch)big image accroding the imgs height and width \n",
    "        \n",
    "        if (blending_mode == \"noBlending\"):\n",
    "            stitch_img[:hl, :wl] = img_left\n",
    "            \n",
    "        # Transform Right image(the coordination of right image) to destination iamge(the coordination of left image) with HomoMat\n",
    "        inv_H = np.linalg.inv(HomoMat)\n",
    "        for i in range(stitch_img.shape[0]):\n",
    "            for j in range(stitch_img.shape[1]):\n",
    "                coor = np.array([j, i, 1])\n",
    "                img_right_coor = inv_H @ coor # the coordination of right image\n",
    "                img_right_coor /= img_right_coor[2]\n",
    "                \n",
    "                # you can try like nearest neighbors or interpolation  \n",
    "                y, x = int(round(img_right_coor[0])), int(round(img_right_coor[1])) # y for width, x for height\n",
    "                \n",
    "                \n",
    "                # if the computed coordination not in the (hegiht, width) of right image, it's not need to be process \n",
    "                if (x < 0 or x >= hr or y < 0 or y >= wr):\n",
    "                    continue\n",
    "                # else we need the tranform for this pixel\n",
    "                stitch_img[i, j] = img_right[x, y]\n",
    "            \n",
    "        \n",
    "        # create the Blender object to blending the image\n",
    "        blender = Blender()\n",
    "        if (blending_mode == \"linearBlending\"):\n",
    "            stitch_img = blender.linearBlending([img_left, stitch_img])\n",
    "        elif (blending_mode == \"linearBlendingWithConstant\"):\n",
    "            stitch_img = blender.linearBlendingWithConstantWidth([img_left, stitch_img])\n",
    "        \n",
    "        # remove the black border\n",
    "        stitch_img = self.removeBlackBorder(stitch_img)\n",
    "        \n",
    "        return stitch_img\n",
    "    \n",
    "    def removeBlackBorder(self, img):\n",
    "        '''\n",
    "        Remove img's the black border \n",
    "        '''\n",
    "        h, w = img.shape[:2]\n",
    "        reduced_h, reduced_w = h, w\n",
    "        # right to left\n",
    "        for col in range(w - 1, -1, -1):\n",
    "            all_black = True\n",
    "            for i in range(h):\n",
    "                if (np.count_nonzero(img[i, col]) > 0):\n",
    "                    all_black = False\n",
    "                    break\n",
    "            if (all_black == True):\n",
    "                reduced_w = reduced_w - 1\n",
    "                \n",
    "        # bottom to top \n",
    "        for row in range(h - 1, -1, -1):\n",
    "            all_black = True\n",
    "            for i in range(reduced_w):\n",
    "                if (np.count_nonzero(img[row, i]) > 0):\n",
    "                    all_black = False\n",
    "                    break\n",
    "            if (all_black == True):\n",
    "                reduced_h = reduced_h - 1\n",
    "        \n",
    "        return img[:reduced_h, :reduced_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe130d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blender:\n",
    "    def linearBlending(self, imgs):\n",
    "        '''\n",
    "        linear Blending(also known as Feathering)\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        img_left_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        img_right_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        \n",
    "        # find the left image and right image mask region(Those not zero pixels)\n",
    "        for i in range(hl):\n",
    "            for j in range(wl):\n",
    "                if np.count_nonzero(img_left[i, j]) > 0:\n",
    "                    img_left_mask[i, j] = 1\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if np.count_nonzero(img_right[i, j]) > 0:\n",
    "                    img_right_mask[i, j] = 1\n",
    "        \n",
    "        # find the overlap mask(overlap region of two image)\n",
    "        overlap_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(img_left_mask[i, j]) > 0 and np.count_nonzero(img_right_mask[i, j]) > 0):\n",
    "                    overlap_mask[i, j] = 1\n",
    "        \n",
    "        # Plot the overlap mask\n",
    "        plt.figure(21)\n",
    "        plt.title(\"overlap_mask\")\n",
    "        plt.imshow(overlap_mask.astype(int), cmap=\"gray\")\n",
    "        \n",
    "        # compute the alpha mask to linear blending the overlap region\n",
    "        alpha_mask = np.zeros((hr, wr)) # alpha value depend on left image\n",
    "        for i in range(hr): \n",
    "            minIdx = maxIdx = -1\n",
    "            for j in range(wr):\n",
    "                if (overlap_mask[i, j] == 1 and minIdx == -1):\n",
    "                    minIdx = j\n",
    "                if (overlap_mask[i, j] == 1):\n",
    "                    maxIdx = j\n",
    "            \n",
    "            if (minIdx == maxIdx): # represent this row's pixels are all zero, or only one pixel not zero\n",
    "                continue\n",
    "                \n",
    "            decrease_step = 1 / (maxIdx - minIdx)\n",
    "            for j in range(minIdx, maxIdx + 1):\n",
    "                alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "        \n",
    "        \n",
    "        \n",
    "        linearBlending_img = np.copy(img_right)\n",
    "        linearBlending_img[:hl, :wl] = np.copy(img_left)\n",
    "        # linear blending\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if ( np.count_nonzero(overlap_mask[i, j]) > 0):\n",
    "                    linearBlending_img[i, j] = alpha_mask[i, j] * img_left[i, j] + (1 - alpha_mask[i, j]) * img_right[i, j]\n",
    "        \n",
    "        return linearBlending_img\n",
    "    def linearBlendingWithConstantWidth(self, imgs):\n",
    "        '''\n",
    "        linear Blending with Constat Width, avoiding ghost region\n",
    "        # you need to determine the size of constant with\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        img_left_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        img_right_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        constant_width = 3 # constant width\n",
    "        \n",
    "        # find the left image and right image mask region(Those not zero pixels)\n",
    "        for i in range(hl):\n",
    "            for j in range(wl):\n",
    "                if np.count_nonzero(img_left[i, j]) > 0:\n",
    "                    img_left_mask[i, j] = 1\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if np.count_nonzero(img_right[i, j]) > 0:\n",
    "                    img_right_mask[i, j] = 1\n",
    "                    \n",
    "        # find the overlap mask(overlap region of two image)\n",
    "        overlap_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(img_left_mask[i, j]) > 0 and np.count_nonzero(img_right_mask[i, j]) > 0):\n",
    "                    overlap_mask[i, j] = 1\n",
    "        \n",
    "        # compute the alpha mask to linear blending the overlap region\n",
    "        alpha_mask = np.zeros((hr, wr)) # alpha value depend on left image\n",
    "        for i in range(hr):\n",
    "            minIdx = maxIdx = -1\n",
    "            for j in range(wr):\n",
    "                if (overlap_mask[i, j] == 1 and minIdx == -1):\n",
    "                    minIdx = j\n",
    "                if (overlap_mask[i, j] == 1):\n",
    "                    maxIdx = j\n",
    "            \n",
    "            if (minIdx == maxIdx): # represent this row's pixels are all zero, or only one pixel not zero\n",
    "                continue\n",
    "                \n",
    "            decrease_step = 1 / (maxIdx - minIdx)\n",
    "            \n",
    "            # Find the middle line of overlapping regions, and only do linear blending to those regions very close to the middle line.\n",
    "            middleIdx = int((maxIdx + minIdx) / 2)\n",
    "            \n",
    "            # left \n",
    "            for j in range(minIdx, middleIdx + 1):\n",
    "                if (j >= middleIdx - constant_width):\n",
    "                    alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "                else:\n",
    "                    alpha_mask[i, j] = 1\n",
    "            # right\n",
    "            for j in range(middleIdx + 1, maxIdx + 1):\n",
    "                if (j <= middleIdx + constant_width):\n",
    "                    alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "                else:\n",
    "                    alpha_mask[i, j] = 0\n",
    "\n",
    "        \n",
    "        linearBlendingWithConstantWidth_img = np.copy(img_right)\n",
    "        linearBlendingWithConstantWidth_img[:hl, :wl] = np.copy(img_left)\n",
    "        # linear blending with constant width\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(overlap_mask[i, j]) > 0):\n",
    "                    linearBlendingWithConstantWidth_img[i, j] = alpha_mask[i, j] * img_left[i, j] + (1 - alpha_mask[i, j]) * img_right[i, j]\n",
    "        \n",
    "        return linearBlendingWithConstantWidth_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Homography:\n",
    "    def solve_homography(self, P, m):\n",
    "        \"\"\"\n",
    "        Solve homography matrix \n",
    "\n",
    "        Args:\n",
    "            P:  Coordinates of the points in the original plane,\n",
    "            m:  Coordinates of the points in the target plane\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            H: Homography matrix \n",
    "        \"\"\"\n",
    "        try:\n",
    "            A = []  \n",
    "            for r in range(len(P)): \n",
    "                #print(m[r, 0])\n",
    "                A.append([-P[r,0], -P[r,1], -1, 0, 0, 0, P[r,0]*m[r,0], P[r,1]*m[r,0], m[r,0]])\n",
    "                A.append([0, 0, 0, -P[r,0], -P[r,1], -1, P[r,0]*m[r,1], P[r,1]*m[r,1], m[r,1]])\n",
    "\n",
    "            u, s, vt = np.linalg.svd(A) # Solve s ystem of linear equations Ah = 0 using SVD\n",
    "            # pick H from last line of vt  \n",
    "            H = np.reshape(vt[8], (3,3))\n",
    "            # normalization, let H[2,2] equals to 1\n",
    "            H = (1/H.item(8)) * H\n",
    "        except:\n",
    "            print(\"Error occur!\")\n",
    "\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    fileNameList = [('hill1', 'hill2')]\n",
    "    for fname1, fname2 in fileNameList:\n",
    "        # Read the img file\n",
    "        src_path = r\"D:\\img\"\n",
    "        fileName1 = fname1\n",
    "        fileName2 = fname2\n",
    "        img_left = cv2.imread(src_path + r'/'+ fileName1 + \".jpg\")\n",
    "        img_right = cv2.imread(src_path + r'/'+ fileName2 + \".jpg\")\n",
    "        \n",
    "        \n",
    "        # The stitch object to stitch the image\n",
    "        blending_mode = \"linearBlending\" # three mode - noBlending、linearBlending、linearBlendingWithConstant\n",
    "        stitcher = Stitcher()\n",
    "        warp_img = stitcher.stitch([img_left, img_right], blending_mode)\n",
    "\n",
    "        # plot the stitched image\n",
    "        plt.figure(13)\n",
    "        plt.title(\"warp_img\")\n",
    "        plt.imshow(warp_img[:,:,::-1].astype(int))\n",
    "\n",
    "        # save the stitched iamge\n",
    "        saveFilePath = \"img/u4.jpg\".format(fileName1, fileName2, blending_mode)\n",
    "        cv2.imwrite(saveFilePath, warp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b73ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameList = [('1', '2')]\n",
    "for fname1, fname2 in fileNameList:\n",
    "        # Read the img file\n",
    "        src_path = r\"D:\\img\"\n",
    "        fileName1 = fname1\n",
    "        fileName2 = fname2\n",
    "        img_left = cv2.imread(src_path + r'/'+ fileName1 + \".jpg\")\n",
    "        img_right = cv2.imread(src_path + r'/'+ fileName2 + \".jpg\")\n",
    "        \n",
    "img = cv2.imread(r\"D:\\img\\1.jpg\")\n",
    "print(np.array(img_left).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1944b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
